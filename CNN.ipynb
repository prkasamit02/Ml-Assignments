{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "H9EU0e8yzFOm",
    "outputId": "fdb25511-f72a-4b12-811c-1bc8b64c54d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with 2 CNN layer , without dropouts, Relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.1945 - acc: 0.9399 - val_loss: 0.0530 - val_acc: 0.9832\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0475 - acc: 0.9856 - val_loss: 0.0372 - val_acc: 0.9870\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0338 - val_acc: 0.9883\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0198 - acc: 0.9940 - val_loss: 0.0357 - val_acc: 0.9882\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0290 - val_acc: 0.9908\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 168s 3ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 0.0284 - val_acc: 0.9912\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 168s 3ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0392 - val_acc: 0.9882\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0386 - val_acc: 0.9896\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 168s 3ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0410 - val_acc: 0.9889\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0381 - val_acc: 0.9896\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0373 - val_acc: 0.9912\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 9.8122e-04 - acc: 0.9997 - val_loss: 0.0359 - val_acc: 0.9909\n",
      "Test loss: 0.03592068427125355\n",
      "Test accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with 3 CNN layers , dropout layer , Maxpooling layer and Relu Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "fv2fmSXX7enz",
    "outputId": "b4dfd9c6-53ad-4e12-b433-ecb5bd03c26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amit.prakash\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\amit.prakash\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\amit.prakash\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.2713 - acc: 0.9150 - val_loss: 0.0577 - val_acc: 0.9817\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0749 - acc: 0.9771 - val_loss: 0.0329 - val_acc: 0.9890\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0572 - acc: 0.9825 - val_loss: 0.0298 - val_acc: 0.9896\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0472 - acc: 0.9859 - val_loss: 0.0334 - val_acc: 0.9889\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0402 - acc: 0.9872 - val_loss: 0.0280 - val_acc: 0.9902\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0344 - acc: 0.9892 - val_loss: 0.0247 - val_acc: 0.9911\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0323 - acc: 0.9902 - val_loss: 0.0218 - val_acc: 0.9923\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0283 - acc: 0.9914 - val_loss: 0.0277 - val_acc: 0.9909\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0251 - val_acc: 0.9918\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 0.0251 - acc: 0.9923 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0256 - val_acc: 0.9910\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0219 - val_acc: 0.9925\n",
      "Test loss: 0.02192042817994079\n",
      "Test accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model1.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(128, (2, 2), activation='relu'))\n",
    "\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(240, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with 3 CNN layers,maxpooling and tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "EvL7zPxmPnBG",
    "outputId": "5329aa6b-e3d2-4e5d-dc69-cf2e98e8abd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 254s 4ms/step - loss: 0.1707 - acc: 0.9479 - val_loss: 0.0541 - val_acc: 0.9824\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 249s 4ms/step - loss: 0.0551 - acc: 0.9829 - val_loss: 0.0341 - val_acc: 0.9886\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0374 - acc: 0.9883 - val_loss: 0.0337 - val_acc: 0.9888\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.0285 - acc: 0.9910 - val_loss: 0.0305 - val_acc: 0.9902\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 206s 3ms/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0296 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 208s 3ms/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.0299 - val_acc: 0.9905\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 207s 3ms/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0277 - val_acc: 0.9919\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 249s 4ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0297 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.0370 - val_acc: 0.9893\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 221s 4ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0296 - val_acc: 0.9916\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 206s 3ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0326 - val_acc: 0.9908\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 206s 3ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0344 - val_acc: 0.9898\n",
      "Test loss: 0.03436766459278697\n",
      "Test accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(2, 2),\n",
    "                 activation='tanh',\n",
    "                 input_shape=input_shape))\n",
    "model2.add(Conv2D(64, (2, 2), activation='tanh'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model2.add(Conv2D(128, (2, 2), activation='tanh'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(240, activation='tanh'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with 3 CNN layers, dropout layer and tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "colab_type": "code",
    "id": "wC5T_GnPKEa3",
    "outputId": "5453362a-247a-4c14-dcfe-046dcc0e682e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.2245 - acc: 0.9280 - val_loss: 0.0494 - val_acc: 0.9836\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 243s 4ms/step - loss: 0.0692 - acc: 0.9787 - val_loss: 0.0323 - val_acc: 0.9904\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 252s 4ms/step - loss: 0.0509 - acc: 0.9842 - val_loss: 0.0275 - val_acc: 0.9912\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0443 - acc: 0.9857 - val_loss: 0.0291 - val_acc: 0.9910\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0386 - acc: 0.9875 - val_loss: 0.0243 - val_acc: 0.9919\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 260s 4ms/step - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0245 - val_acc: 0.9921\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0306 - acc: 0.9899 - val_loss: 0.0206 - val_acc: 0.9935\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 242s 4ms/step - loss: 0.0273 - acc: 0.9911 - val_loss: 0.0232 - val_acc: 0.9924\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 251s 4ms/step - loss: 0.0231 - acc: 0.9923 - val_loss: 0.0228 - val_acc: 0.9924\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 253s 4ms/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.0201 - val_acc: 0.9926\n",
      "Test loss: 0.020068910302619043\n",
      "Test accuracy: 0.9926\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='tanh',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "\n",
    "model3.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Conv2D(120, (3, 3), activation='tanh'))\n",
    "\n",
    "\n",
    "\n",
    "model3.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model3.add(Dropout(0.25))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(256, activation='tanh'))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x_train, y_train,\n",
    "          batch_size=125,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+---------+----------+--------------+\n",
      "| No. of CNN layers | Activation Function | DropOut | Test AUC | Validate AUC |\n",
      "+-------------------+---------------------+---------+----------+--------------+\n",
      "|         2         |         Relu        |    NO   |  0.9997  |    0.9909    |\n",
      "|         3         |         Relu        |   Yes   |  0.9936  |    0.9925    |\n",
      "|         2         |         Tanh        |    NO   |  0.9992  |    0.9898    |\n",
      "|         3         |         Tanh        |   Yes   |  0.9923  |    0.9926    |\n",
      "+-------------------+---------------------+---------+----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"No. of CNN layers\", \"Activation Function\", \"DropOut\",\"Test AUC\", \"Validate AUC\"]\n",
    "\n",
    "x.add_row([\"2\",\"Relu\" ,\"NO\", 0.9997, 0.9909])\n",
    "x.add_row([\"3\",\"Relu\",\"Yes\" , 0.9936, 0.9925])\n",
    "x.add_row([\"2\",\"Tanh\" ,\"NO\", 0.9992, 0.9898])\n",
    "x.add_row([\"3\", \"Tanh\",\"Yes\", 0.9923,0.9926])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above pritty table we can conclude that Test Auc and Validate Auc for model 4 i.e model with 3 CNN layers, dropout layers and tanh  as activation function has test and validate accuracy  approximatily same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_MNIST_(1) (1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
